{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def load_postgres_instance_datasource_asset(context):\n",
    "    \"\"\" Cria ou carrega o Datasource, o Data Asset e o objeto Batch Request para a validação \n",
    "    com o Great Expectations. É a primeira etapa do workflow, sendo a definição dos dados\n",
    "    que serão validados. Esta função conecta a uma instância de Banco de Dados Postgres.\n",
    "\n",
    "    Args:\n",
    "        context (gx.Context): Objeto configurado de Contexto do projeto\n",
    "\n",
    "    Returns:\n",
    "        gx.Batch_Request: objeto de batch_request com definição dos dados a serem processados.\n",
    "    \"\"\"\n",
    "    # Environment\n",
    "    dotenv.load_dotenv()\n",
    "    POSTGRES_USER = os.environ.get('POSTGRES_USER')\n",
    "    POSTGRES_PASSWORD = os.environ.get('POSTGRES_PASSWORD')\n",
    "    POSTGRES_PORT = os.environ.get('POSTGRES_PORT_CONTAINER')\n",
    "    POSTGRES_HOST = os.environ.get('POSTGRES_HOST')\n",
    "\n",
    "    POSTGRES_URI = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/postgres\"\n",
    "\n",
    "\n",
    "    # Datasource - engine\n",
    "    datasource_name = \"postgres_src\"\n",
    "    datasource = context.datasources.get('airbnb', None)\n",
    "    if datasource == None:\n",
    "        datasource = context.sources.add_postgres(name=datasource_name, connection_string=POSTGRES_URI, )\n",
    "\n",
    "\n",
    "    # Data Asset - connection\n",
    "    asset_name = 'listings_asset'\n",
    "    asset_table_name = \"g1_listings\"  # SQL table\n",
    "    list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "    if asset_name in list_asset_names:\n",
    "        table_asset = datasource.get_asset('reviews', None)\n",
    "    else:\n",
    "        table_asset = datasource.add_table_asset(name=asset_name, table_name=asset_table_name, schema_name='raw')\n",
    "        # add_query_asset\n",
    "    data_asset = context.get_datasource( datasource_name ).get_asset( asset_name )\n",
    "\n",
    "    batch_request = table_asset.build_batch_request()\n",
    "    return batch_request\n",
    "\n",
    "\n",
    "\n",
    "def load_csv_datasource_asset_raw(context, datasource_name: str, asset_name:str, layer_name='raw'):\n",
    "    \"\"\" Cria ou carrega o Datasource, o Data Asset e o objeto Batch Request para a validação \n",
    "    com o Great Expectations. É a primeira etapa do workflow, sendo a definição dos dados\n",
    "    que serão validados.\n",
    "\n",
    "    Args:\n",
    "        context (gx.Context): Objeto configurado de Contexto do projeto\n",
    "        datasource_name (str): Nome do Datasource.\n",
    "        asset_name (str): Nome do Asset\n",
    "        layer_name (str, optional): Nome da camada de dados (raw, trusted ou specs). Defaults to 'raw'.\n",
    "\n",
    "    Returns:\n",
    "        gx.Batch_Request: objeto de batch_request com definição dos dados a serem processados.\n",
    "    \"\"\"\n",
    "    file_data_regex = asset_name + '\\.csv\\.gz'\n",
    "    expectation_suite_name_str = f'{layer_name}_{asset_name}'\n",
    "    run_name = f'{layer_name}.{asset_name}'\n",
    "    \n",
    "    # Datasource - engine\n",
    "    datasource = context.datasources.get(datasource_name, None)\n",
    "    if datasource == None:\n",
    "        datasource = context.sources.add_pandas_filesystem(datasource_name, base_directory='./data')\n",
    "\n",
    "\n",
    "    # Data Asset - connection\n",
    "    list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "    if asset_name in list_asset_names:\n",
    "        table_asset = datasource.get_asset(asset_name)\n",
    "    else:\n",
    "        table_asset = datasource.add_csv_asset(asset_name, batching_regex=file_data_regex)\n",
    "\n",
    "    batch_request = table_asset.build_batch_request()\n",
    "    return batch_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoramento RAW - Reviews\n",
    "def suite_monitoring_execution(asset_name: str, datasource_name='airbnb', data_context_path = '.'):\n",
    "    \"\"\" Função de execução do Monitoramento para um dado CSV. Cria o suite ou obtém o existente com o nome\n",
    "    para criar o Checkpoint de Validação da Qualidade dos dados. Por fim, garante a execução do Checkpoint.\n",
    "\n",
    "    Args:\n",
    "        asset_name (str): Nome do asset\n",
    "        datasource_name (str, optional): Nome do Datasource a ser criado ou usado.. Defaults to 'airbnb'.\n",
    "        data_context_path (str, optional): Diretório do Data Context. Defaults to '.'.\n",
    "\n",
    "    Returns:\n",
    "        checkpoint_result: Resultado da execução do Checkpoint.\n",
    "    \"\"\"\n",
    "    suite_name = f'raw_{asset_name}'\n",
    "\n",
    "    # Data Context\n",
    "    context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "    # Batch request\n",
    "    batch_request = load_csv_datasource_asset_raw(context=context, datasource_name=datasource_name, asset_name=asset_name, layer_name='raw')\n",
    "\n",
    "    # Suite\n",
    "    if suite_name not in context.list_expectation_suite_names():\n",
    "        context.add_or_update_expectation_suite(suite_name)\n",
    "\n",
    "    # Checkpoint Validation\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=f\"{suite_name}\",\n",
    "        validations=[{\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": suite_name,\n",
    "            }])\n",
    "\n",
    "    checkpoint_result = checkpoint.run(run_name=suite_name)\n",
    "    return checkpoint_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff69adb3a2ff441eb3c4e65789c25716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076986b61ab74552ba7e960c24afc072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe39dbb6c5f477faad62d003fa208ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validação das Bases do RAW em sua totalidade\n",
    "\n",
    "# Suites Enviroment\n",
    "context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "src_suites = os.path.join('.', 'utils', 'data-quality-profilers')\n",
    "dst_suites = os.path.join('.', 'gx', 'expectations')\n",
    "shutil.copytree(src_suites, dst_suites, dirs_exist_ok=True)\n",
    "\n",
    "checkpoint_result_raw_reviews = suite_monitoring_execution(asset_name='reviews')\n",
    "checkpoint_result_raw_reviews = suite_monitoring_execution(asset_name='calendar')\n",
    "checkpoint_result_raw_listings = suite_monitoring_execution(asset_name='listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistência do Relatório\n",
    "src_path = '.\\gx\\uncommitted\\data_docs\\local_site\\index.html'\n",
    "dst_folder = '.\\doc\\data_quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import great_expectations as gx\n",
    "# from great_expectations.exceptions import DataContextError\n",
    "# import pandas as pd\n",
    "# import dotenv\n",
    "# import os\n",
    "\n",
    "# # Environment\n",
    "# dotenv.load_dotenv()\n",
    "# POSTGRES_USER = os.environ.get('POSTGRES_USER')\n",
    "# POSTGRES_PASSWORD = os.environ.get('POSTGRES_PASSWORD')\n",
    "# POSTGRES_PORT = os.environ.get('POSTGRES_PORT_CONTAINER')\n",
    "# POSTGRES_HOST = os.environ.get('POSTGRES_HOST')\n",
    "\n",
    "# POSTGRES_URI = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/postgres\"\n",
    "\n",
    "\n",
    "# # Data Context\n",
    "# data_context_path = '.'\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "# # Datasource - engine\n",
    "# datasource_name = \"postgres_src\"\n",
    "# try:\n",
    "#     datasource = context.sources.add_postgres(name=datasource_name, connection_string=POSTGRES_URI, )\n",
    "# except DataContextError:\n",
    "#     pass\n",
    "\n",
    "# # Data Asset - connection\n",
    "# asset_name = 'listings_asset_11'\n",
    "# asset_table_name = \"g1_listings\"  # SQL table\n",
    "# table_asset = datasource.add_table_asset(name=asset_name, table_name=asset_table_name, schema_name='raw')\n",
    "# # add_query_asset\n",
    "# # (name=asset_name, table_name=asset_table_name)\n",
    "# data_asset = context.get_datasource( datasource_name ).get_asset( asset_name )\n",
    "# batch_request = table_asset.build_batch_request()\n",
    "\n",
    "# # Suite\n",
    "# context.add_or_update_expectation_suite(\"my_expectation_suite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Context\n",
    "# asset_name='reviews'\n",
    "# layer_name='raw'\n",
    "# datasource_name='airbnb'\n",
    "# suite_name = f'raw_{asset_name}'\n",
    "\n",
    "\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "\n",
    "# file_data_regex = asset_name + '\\.csv\\.gz'\n",
    "# expectation_suite_name_str = f'{layer_name}_{asset_name}'\n",
    "# run_name = f'{layer_name}.{asset_name}'\n",
    "\n",
    "# # Datasource - engine\n",
    "# datasource = context.datasources.get(datasource_name, None)\n",
    "# if datasource == None:\n",
    "#     datasource = context.sources.add_pandas_filesystem(datasource_name, base_directory='./data')\n",
    "\n",
    "\n",
    "# # Data Asset - connection\n",
    "# list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "# if asset_name in list_asset_names:\n",
    "#     table_asset = datasource.get_asset('reviews')\n",
    "# else:\n",
    "#     table_asset = datasource.add_csv_asset(asset_name, batching_regex=file_data_regex)\n",
    "\n",
    "# batch_request = table_asset.build_batch_request()\n",
    "\n",
    "# # Suite\n",
    "\n",
    "# if suite_name not in context.list_expectation_suite_names():\n",
    "#     context.add_or_update_expectation_suite(suite_name)\n",
    "\n",
    "# # Checkpoint Validation\n",
    "# checkpoint = context.add_or_update_checkpoint(\n",
    "#     name=f\"{suite_name}\",\n",
    "#     validations=[{\n",
    "#         \"batch_request\": batch_request,\n",
    "#         \"expectation_suite_name\": suite_name,\n",
    "#         }])\n",
    "\n",
    "# checkpoint_result = checkpoint.run(run_name=suite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Context\n",
    "data_context_path = '.'\n",
    "context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "# Batch request\n",
    "# batch_request = load_postgres_instance_datasource_asset(context=context)\n",
    "batch_request_raw_reviews = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='reviews', layer_name='raw')\n",
    "# batch_request_raw_listings = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='listings', layer_name='raw')\n",
    "# batch_request_raw_calendar = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='calendar', layer_name='raw')\n",
    "\n",
    "# Suite\n",
    "context.add_or_update_expectation_suite(\"my_expectation_suite\")\n",
    "\n",
    "\n",
    "# Validator\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=\"my_expectation_suite\",\n",
    ")\n",
    "validator.head()\n",
    "\n",
    "# validator.expect_column_values_to_not_be_null(column=\"vendor_id\")\n",
    "# validator.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIÁVEIS ALVOS\n",
    "\n",
    "host_neighbourhood ,\n",
    "neighbourhood_cleansed ,\n",
    "host_is_superhost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
