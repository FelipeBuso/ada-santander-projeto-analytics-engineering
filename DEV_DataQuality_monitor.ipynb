{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import great_expectations as gx\n",
    "# import pandas as pd\n",
    "# import dotenv\n",
    "# import shutil\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# def load_postgres_instance_datasource_asset(context):\n",
    "#     \"\"\" Cria ou carrega o Datasource, o Data Asset e o objeto Batch Request para a validação \n",
    "#     com o Great Expectations. É a primeira etapa do workflow, sendo a definição dos dados\n",
    "#     que serão validados. Esta função conecta a uma instância de Banco de Dados Postgres.\n",
    "\n",
    "#     Args:\n",
    "#         context (gx.Context): Objeto configurado de Contexto do projeto\n",
    "\n",
    "#     Returns:\n",
    "#         gx.Batch_Request: objeto de batch_request com definição dos dados a serem processados.\n",
    "#     \"\"\"\n",
    "#     # Environment\n",
    "#     dotenv.load_dotenv()\n",
    "#     POSTGRES_USER = os.environ.get('POSTGRES_USER')\n",
    "#     POSTGRES_PASSWORD = os.environ.get('POSTGRES_PASSWORD')\n",
    "#     POSTGRES_PORT = os.environ.get('POSTGRES_PORT_CONTAINER')\n",
    "#     POSTGRES_HOST = os.environ.get('POSTGRES_HOST')\n",
    "\n",
    "#     POSTGRES_URI = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/postgres\"\n",
    "\n",
    "\n",
    "#     # Datasource - engine\n",
    "#     datasource_name = \"postgres_src\"\n",
    "#     datasource = context.datasources.get(datasource_name, None)\n",
    "#     if datasource == None:\n",
    "#         datasource = context.sources.add_postgres(name=datasource_name, connection_string=POSTGRES_URI, )\n",
    "\n",
    "\n",
    "#     # Data Asset - connection\n",
    "#     asset_name = 'listings_asset'\n",
    "#     asset_table_name = \"g1_listings\"  # SQL table\n",
    "#     list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "#     if asset_name in list_asset_names:\n",
    "#         table_asset = datasource.get_asset('reviews', None)\n",
    "#     else:\n",
    "#         table_asset = datasource.add_table_asset(name=asset_name, table_name=asset_table_name, schema_name='raw')\n",
    "#         # add_query_asset\n",
    "#     data_asset = context.get_datasource( datasource_name ).get_asset( asset_name )\n",
    "\n",
    "#     batch_request = table_asset.build_batch_request()\n",
    "#     return batch_request\n",
    "\n",
    "\n",
    "\n",
    "# def load_csv_datasource_asset_raw(context, datasource_name: str, asset_name:str, layer_name='raw'):\n",
    "#     \"\"\" Cria ou carrega o Datasource, o Data Asset e o objeto Batch Request para a validação \n",
    "#     com o Great Expectations. É a primeira etapa do workflow, sendo a definição dos dados\n",
    "#     que serão validados.\n",
    "\n",
    "#     Args:\n",
    "#         context (gx.Context): Objeto configurado de Contexto do projeto\n",
    "#         datasource_name (str): Nome do Datasource.\n",
    "#         asset_name (str): Nome do Asset\n",
    "#         layer_name (str, optional): Nome da camada de dados (raw, trusted ou specs). Defaults to 'raw'.\n",
    "\n",
    "#     Returns:\n",
    "#         gx.Batch_Request: objeto de batch_request com definição dos dados a serem processados.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     file_data_regex = asset_name + '\\.csv\\.gz'\n",
    "    \n",
    "#     # Datasource - engine\n",
    "#     datasource = context.datasources.get(datasource_name, None)\n",
    "#     if datasource == None:\n",
    "#         datasource = context.sources.add_pandas_filesystem(datasource_name, base_directory='./data')\n",
    "\n",
    "\n",
    "#     # Data Asset - connection\n",
    "#     list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "#     if asset_name in list_asset_names:\n",
    "#         table_asset = datasource.get_asset(asset_name)\n",
    "#     else:\n",
    "#         table_asset = datasource.add_csv_asset(asset_name, batching_regex=file_data_regex)\n",
    "\n",
    "#     batch_request = table_asset.build_batch_request()\n",
    "#     return batch_request\n",
    "\n",
    "\n",
    "# def load_df_datasource_asset_trusted(context, df, datasource_name: str, asset_name:str):\n",
    "#     \"\"\" Cria ou carrega o Datasource, o Data Asset e o objeto Batch Request para a validação \n",
    "#     com o Great Expectations. É a primeira etapa do workflow, sendo a definição dos dados\n",
    "#     que serão validados.\n",
    "\n",
    "#     Args:\n",
    "#         context (gx.Context): Objeto configurado de Contexto do projeto\n",
    "#         datasource_name (str): Nome do Datasource.\n",
    "#         asset_name (str): Nome do Asset\n",
    "#         layer_name (str, optional): Nome da camada de dados (raw, trusted ou specs). Defaults to 'raw'.\n",
    "\n",
    "#     Returns:\n",
    "#         gx.Batch_Request: objeto de batch_request com definição dos dados a serem processados.\n",
    "#     \"\"\"\n",
    "#     # Datasource - engine\n",
    "#     datasource = context.datasources.get(datasource_name, None)\n",
    "#     if datasource == None:\n",
    "#         datasource = context.sources.add_pandas(datasource_name)\n",
    "\n",
    "\n",
    "#     # Data Asset - connection\n",
    "#     list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "#     if asset_name in list_asset_names:\n",
    "#         data_asset = datasource.get_asset(asset_name)\n",
    "#     else:\n",
    "#         data_asset = datasource.add_dataframe_asset(name=asset_name)\n",
    "\n",
    "#     batch_request = data_asset.build_batch_request(dataframe=df)\n",
    "#     return batch_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Monitoramento RAW - Reviews\n",
    "# def suite_monitoring_execution(\n",
    "#         asset_name: str, \n",
    "#         datasource_name='airbnb', \n",
    "#         data_context_path = '.', \n",
    "#         layer_name='raw', \n",
    "#         suite_name_str=None,\n",
    "#         batch_request_input=None):\n",
    "#     \"\"\" Função de execução do Monitoramento para um dado CSV. Cria o suite ou obtém o existente com o nome\n",
    "#     para criar o Checkpoint de Validação da Qualidade dos dados. Por fim, garante a execução do Checkpoint.\n",
    "\n",
    "#     Args:\n",
    "#         asset_name (str): Nome do asset\n",
    "#         datasource_name (str, optional): Nome do Datasource a ser criado ou usado.. Defaults to 'airbnb'.\n",
    "#         data_context_path (str, optional): Diretório do Data Context. Defaults to '.'.\n",
    "\n",
    "#     Returns:\n",
    "#         checkpoint_result: Resultado da execução do Checkpoint.\n",
    "#     \"\"\"\n",
    "#     if suite_name_str == None:\n",
    "#         suite_name = f'{layer_name}_{asset_name}'\n",
    "#     else:\n",
    "#         suite_name = f'{layer_name}_{suite_name_str}'\n",
    "\n",
    "#     # Data Context\n",
    "#     context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "#     # Batch request\n",
    "#     if batch_request_input == None:\n",
    "#         batch_request = load_csv_datasource_asset_raw(\n",
    "#             context=context, datasource_name=datasource_name, asset_name=asset_name, layer_name=layer_name)\n",
    "#     else:\n",
    "#         batch_request = batch_request_input\n",
    "\n",
    "#     # Suite\n",
    "#     if suite_name not in context.list_expectation_suite_names():\n",
    "#         context.add_or_update_expectation_suite(suite_name)\n",
    "\n",
    "#     # Checkpoint Validation\n",
    "#     checkpoint = context.add_or_update_checkpoint(\n",
    "#         name=f\"{suite_name}\",\n",
    "#         validations=[{\n",
    "#             \"batch_request\": batch_request,\n",
    "#             \"expectation_suite_name\": suite_name,\n",
    "#             }])\n",
    "\n",
    "#     checkpoint_result = checkpoint.run(run_name=suite_name)\n",
    "#     return checkpoint_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d77e38909e74284aed4deffc5a6ee0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdce10975124969af0690d4481f3605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04b1d9b338d4d15a3038554bddfae5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03b3ec4aecd402a9fd592e7ddcc664d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "import shutil\n",
    "import os\n",
    "from utils.utils_data_quality import suite_monitoring_execution\n",
    "\n",
    "\n",
    "# Validação das Bases do RAW em sua totalidade\n",
    "\n",
    "# Suites Enviroment\n",
    "context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "src_suites = os.path.join('.', 'utils', 'data-quality-profilers')\n",
    "dst_suites = os.path.join('.', 'gx', 'expectations')\n",
    "shutil.copytree(src_suites, dst_suites, dirs_exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_result_raw_reviews = suite_monitoring_execution(asset_name='reviews')\n",
    "checkpoint_result_raw_calendar = suite_monitoring_execution(asset_name='calendar')\n",
    "checkpoint_result_raw_listings = suite_monitoring_execution(asset_name='listings')\n",
    "\n",
    "checkpoint_result_raw_listings_targeted = suite_monitoring_execution(asset_name='listings', suite_name_str='listings_targeted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39d0ca2819f4c81847499c60f851079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from utils.utils_data_quality import suite_monitoring_execution\n",
    "\n",
    "# TRUSTED\n",
    "context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "\n",
    "checkpoint_result_trusted_listings_targeted = suite_monitoring_execution(\n",
    "    layer_name='trusted', asset_name='trusted_listings', suite_name_str='listings_targeted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import great_expectations as gx\n",
    "# import pandas as pd\n",
    "\n",
    "# # Ingestão dos dados tratados\n",
    "# df_tratados = pd.read_csv(r'.\\data\\teste\\listings.csv.gz', compression='gzip', sep=',')\n",
    "\n",
    "# # TRUSTED\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "\n",
    "# batch_request_input = load_df_datasource_asset_trusted(context, datasource_name='airbnb_df', df=df_tratados, asset_name='trusted_listings')\n",
    "\n",
    "# checkpoint_result_trusted_listings_targeted = suite_monitoring_execution(\n",
    "#     layer_name='trusted', asset_name='trusted_listings', suite_name_str='listings_targeted', batch_request_input=batch_request_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import great_expectations as gx\n",
    "# from great_expectations.exceptions import DataContextError\n",
    "# import pandas as pd\n",
    "# import dotenv\n",
    "# import os\n",
    "\n",
    "# # Environment\n",
    "# dotenv.load_dotenv()\n",
    "# POSTGRES_USER = os.environ.get('POSTGRES_USER')\n",
    "# POSTGRES_PASSWORD = os.environ.get('POSTGRES_PASSWORD')\n",
    "# POSTGRES_PORT = os.environ.get('POSTGRES_PORT_CONTAINER')\n",
    "# POSTGRES_HOST = os.environ.get('POSTGRES_HOST')\n",
    "\n",
    "# POSTGRES_URI = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/postgres\"\n",
    "\n",
    "\n",
    "# # Data Context\n",
    "# data_context_path = '.'\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "# # Datasource - engine\n",
    "# datasource_name = \"postgres_src\"\n",
    "# try:\n",
    "#     datasource = context.sources.add_postgres(name=datasource_name, connection_string=POSTGRES_URI, )\n",
    "# except DataContextError:\n",
    "#     pass\n",
    "\n",
    "# # Data Asset - connection\n",
    "# asset_name = 'listings_asset_11'\n",
    "# asset_table_name = \"g1_listings\"  # SQL table\n",
    "# table_asset = datasource.add_table_asset(name=asset_name, table_name=asset_table_name, schema_name='raw')\n",
    "# # add_query_asset\n",
    "# # (name=asset_name, table_name=asset_table_name)\n",
    "# data_asset = context.get_datasource( datasource_name ).get_asset( asset_name )\n",
    "# batch_request = table_asset.build_batch_request()\n",
    "\n",
    "# # Suite\n",
    "# context.add_or_update_expectation_suite(\"my_expectation_suite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Context\n",
    "# asset_name='reviews'\n",
    "# layer_name='raw'\n",
    "# datasource_name='airbnb'\n",
    "# suite_name = f'raw_{asset_name}'\n",
    "\n",
    "\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir='.')\n",
    "\n",
    "# file_data_regex = asset_name + '\\.csv\\.gz'\n",
    "# expectation_suite_name_str = f'{layer_name}_{asset_name}'\n",
    "# run_name = f'{layer_name}.{asset_name}'\n",
    "\n",
    "# # Datasource - engine\n",
    "# datasource = context.datasources.get(datasource_name, None)\n",
    "# if datasource == None:\n",
    "#     datasource = context.sources.add_pandas_filesystem(datasource_name, base_directory='./data')\n",
    "\n",
    "\n",
    "# # Data Asset - connection\n",
    "# list_asset_names = [asset_obj.name for asset_obj in datasource.assets]\n",
    "# if asset_name in list_asset_names:\n",
    "#     table_asset = datasource.get_asset('reviews')\n",
    "# else:\n",
    "#     table_asset = datasource.add_csv_asset(asset_name, batching_regex=file_data_regex)\n",
    "\n",
    "# batch_request = table_asset.build_batch_request()\n",
    "\n",
    "# # Suite\n",
    "\n",
    "# if suite_name not in context.list_expectation_suite_names():\n",
    "#     context.add_or_update_expectation_suite(suite_name)\n",
    "\n",
    "# # Checkpoint Validation\n",
    "# checkpoint = context.add_or_update_checkpoint(\n",
    "#     name=f\"{suite_name}\",\n",
    "#     validations=[{\n",
    "#         \"batch_request\": batch_request,\n",
    "#         \"expectation_suite_name\": suite_name,\n",
    "#         }])\n",
    "\n",
    "# checkpoint_result = checkpoint.run(run_name=suite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Context\n",
    "# data_context_path = '.'\n",
    "# context = gx.data_context.FileDataContext.create(project_root_dir=data_context_path)\n",
    "\n",
    "# # Batch request\n",
    "# # batch_request = load_postgres_instance_datasource_asset(context=context)\n",
    "# batch_request_raw_reviews = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='reviews', layer_name='raw')\n",
    "# # batch_request_raw_listings = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='listings', layer_name='raw')\n",
    "# # batch_request_raw_calendar = load_csv_datasource_asset_raw(context=context, datasource_name='airbnb', asset_name='calendar', layer_name='raw')\n",
    "\n",
    "# # Suite\n",
    "# context.add_or_update_expectation_suite(\"my_expectation_suite\")\n",
    "\n",
    "\n",
    "# # Validator\n",
    "# validator = context.get_validator(\n",
    "#     batch_request=batch_request,\n",
    "#     expectation_suite_name=\"my_expectation_suite\",\n",
    "# )\n",
    "# validator.head()\n",
    "\n",
    "# validator.expect_column_values_to_not_be_null(column=\"vendor_id\")\n",
    "# validator.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIÁVEIS ALVOS\n",
    "\n",
    "# host_neighbourhood ,\n",
    "# neighbourhood_cleansed ,\n",
    "# host_is_superhost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
